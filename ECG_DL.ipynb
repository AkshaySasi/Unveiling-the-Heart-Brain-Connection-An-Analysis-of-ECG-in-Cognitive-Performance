{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zjHNv2kyOjU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from scipy.signal import resample\n",
        "import torch\n",
        "from collections import Counter\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(42)\n",
        "\n",
        "# === Load ECG Data ===\n",
        "with open(\"/content/drive/MyDrive/output_ecg_data/processed_ecg_data.pkl\", \"rb\") as f:\n",
        "    data_dict = pickle.load(f)\n",
        "data = data_dict[\"data\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Signal Utilities ===\n",
        "def clean_signals(X):\n",
        "    X = np.nan_to_num(X)\n",
        "    return (X - np.mean(X, axis=1, keepdims=True)) / (np.std(X, axis=1, keepdims=True) + 1e-8)\n",
        "\n",
        "def downsample_signals(X, target_len=2000):\n",
        "    return np.array([resample(sig, target_len) for sig in X])\n",
        "\n",
        "# === Custom Dataset ===\n",
        "class ECGDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
        "\n",
        "# === Model 1: 1D CNN ===\n",
        "class ECG1DCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 44, 4, padding=2), nn.ReLU(), nn.BatchNorm1d(44), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(44, 57, 7, padding=3), nn.ReLU(), nn.BatchNorm1d(57), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(57, 128, 3, padding=1), nn.ReLU(), nn.BatchNorm1d(128), nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(nn.Flatten(), nn.Dropout(0.3), nn.Linear(128, num_classes))\n",
        "    def forward(self, x): return self.fc(self.cnn(x))\n",
        "\n",
        "# === Model 2: BiLSTM ===\n",
        "class ECG_BiLSTM(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=1, hidden_size=128, num_layers=2, bidirectional=True,\n",
        "                            batch_first=True, dropout=0.3)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 2, 128), nn.ReLU(), nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x.transpose(1, 2))\n",
        "        out = F.adaptive_avg_pool1d(out.transpose(1, 2), 1).squeeze(-1)\n",
        "        return self.fc(out)\n",
        "\n",
        "class ECG_Transformer(nn.Module):\n",
        "    def __init__(self, num_classes, input_dim=1, seq_len=2000, d_model=64, nhead=4, num_layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(input_dim, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, seq_len, d_model))\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input x: [batch_size, 1, seq_len]\n",
        "        x = x.squeeze(1)                  # [batch, seq_len]\n",
        "        x = x.unsqueeze(-1)              # [batch, seq_len, 1]\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer(x)          # [batch, seq_len, d_model]\n",
        "        x = x.transpose(1, 2)            # [batch, d_model, seq_len] for pooling\n",
        "        x = self.global_pool(x)          # [batch, d_model, 1]\n",
        "        return self.classifier(x)        # [batch, num_classes]\n",
        "\n",
        "\n",
        "def train_model(X, y, label_names, model_class, model_name, num_epochs=15, batch_size=64, patience=5):\n",
        "    print(f\"\\n‚öôÔ∏è Training {model_name} with Early Stopping...\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)\n",
        "    X_train, y_train = RandomOverSampler().fit_resample(X_train, y_train)\n",
        "\n",
        "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(ECGDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(ECGDataset(X_test, y_test), batch_size=batch_size)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model_class(num_classes=len(label_names)).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "    # Early stopping\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(X_batch), y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Validation loss\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                val_loss += criterion(model(X_batch), y_batch).item()\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        print(f\"üß† Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Check early stopping\n",
        "        if avg_val_loss < best_loss:\n",
        "            best_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "            best_model_state = model.state_dict()  # Save best model weights\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"‚èπÔ∏è Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "\n",
        "    # Final Evaluation\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            pred = model(X_batch).argmax(dim=1).cpu().numpy()\n",
        "            y_true.extend(y_batch.numpy())\n",
        "            y_pred.extend(pred)\n",
        "\n",
        "    print(f\"\\n‚úÖ Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(\"\\n‚úÖ Classification Report:\\n\", classification_report(y_true, y_pred, target_names=label_names))\n",
        "    print(\"‚úÖ Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "    # Confusion matrix visualization\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "-DadR4ERyQIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Prepare Memory Classifier Data ===\n",
        "X_mem, y_mem = [], []\n",
        "memory_label_map = { \"Five-Memory\": 0, \"Nine-Memory\": 1, \"Thirteen-Memory\": 2 }\n",
        "for subj_data in data:\n",
        "    for cond_idx, condition in enumerate([\"Five\", \"Nine\", \"Thirteen\"]):\n",
        "        for subcond_idx in [1, 2]:\n",
        "            for trial_idx in range(54):\n",
        "                signal = subj_data[cond_idx, subcond_idx, trial_idx]\n",
        "                if not np.isnan(signal).all():\n",
        "                    X_mem.append(signal)\n",
        "                    y_mem.append(memory_label_map[f\"{condition}-Memory\"])\n",
        "\n",
        "X_mem = downsample_signals(clean_signals(np.array(X_mem)))\n",
        "label_names_mem = list(memory_label_map.keys())\n",
        "# === Train all 3 Models for Memory Classification ===\n",
        "train_model(X_mem, np.array(y_mem), label_names_mem, ECG1DCNN, \"1D_CNN_Memory\")\n",
        "train_model(X_mem, np.array(y_mem), label_names_mem, ECG_BiLSTM, \"BiLSTM_Memory\")\n",
        "train_model(X_mem, np.array(y_mem), label_names_mem, ECG_Transformer, \"Transformer_Memory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMVl1JMEyTG1",
        "outputId": "2c7fcc6e-0a28-4e8a-abb7-7d08b3562943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚öôÔ∏è Training 1D_CNN_Memory with Early Stopping...\n",
            "üß† Epoch 1/15 | Train Loss: 0.2702 | Val Loss: 0.1833\n",
            "üß† Epoch 2/15 | Train Loss: 0.1652 | Val Loss: 0.1315\n",
            "üß† Epoch 3/15 | Train Loss: 0.1322 | Val Loss: 0.1283\n",
            "üß† Epoch 4/15 | Train Loss: 0.1102 | Val Loss: 0.0856\n",
            "üß† Epoch 5/15 | Train Loss: 0.1035 | Val Loss: 0.1019\n",
            "üß† Epoch 6/15 | Train Loss: 0.0866 | Val Loss: 0.0730\n",
            "üß† Epoch 7/15 | Train Loss: 0.0762 | Val Loss: 0.0878\n",
            "üß† Epoch 8/15 | Train Loss: 0.0772 | Val Loss: 0.0748\n",
            "üß† Epoch 9/15 | Train Loss: 0.0770 | Val Loss: 0.1181\n",
            "üß† Epoch 10/15 | Train Loss: 0.0855 | Val Loss: 0.0707\n",
            "üß† Epoch 11/15 | Train Loss: 0.0631 | Val Loss: 0.0984\n",
            "üß† Epoch 12/15 | Train Loss: 0.0611 | Val Loss: 0.0669\n",
            "üß† Epoch 13/15 | Train Loss: 0.0599 | Val Loss: 0.0492\n",
            "üß† Epoch 14/15 | Train Loss: 0.0624 | Val Loss: 0.0977\n",
            "üß† Epoch 15/15 | Train Loss: 0.0595 | Val Loss: 0.0533\n",
            "\n",
            "‚úÖ Accuracy: 0.9834\n",
            "\n",
            "‚úÖ Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "    Five-Memory       0.99      1.00      0.99       599\n",
            "    Nine-Memory       0.99      0.97      0.98       585\n",
            "Thirteen-Memory       0.98      0.98      0.98       564\n",
            "\n",
            "       accuracy                           0.98      1748\n",
            "      macro avg       0.98      0.98      0.98      1748\n",
            "   weighted avg       0.98      0.98      0.98      1748\n",
            "\n",
            "‚úÖ Confusion Matrix:\n",
            " [[598   1   0]\n",
            " [  3 569  13]\n",
            " [  6   6 552]]\n",
            "\n",
            "‚öôÔ∏è Training BiLSTM_Memory with Early Stopping...\n",
            "üß† Epoch 1/15 | Train Loss: 0.8679 | Val Loss: 0.4994\n",
            "üß† Epoch 2/15 | Train Loss: 0.3993 | Val Loss: 0.3148\n",
            "üß† Epoch 3/15 | Train Loss: 0.2232 | Val Loss: 0.1976\n",
            "üß† Epoch 4/15 | Train Loss: 0.2013 | Val Loss: 0.2200\n",
            "üß† Epoch 5/15 | Train Loss: 0.2030 | Val Loss: 0.1792\n",
            "üß† Epoch 6/15 | Train Loss: 0.1778 | Val Loss: 0.1711\n",
            "üß† Epoch 7/15 | Train Loss: 0.1729 | Val Loss: 0.1740\n",
            "üß† Epoch 8/15 | Train Loss: 0.1705 | Val Loss: 0.1661\n",
            "üß† Epoch 9/15 | Train Loss: 0.1640 | Val Loss: 0.1578\n",
            "üß† Epoch 10/15 | Train Loss: 0.1554 | Val Loss: 0.1493\n",
            "üß† Epoch 11/15 | Train Loss: 0.1497 | Val Loss: 0.1377\n",
            "üß† Epoch 12/15 | Train Loss: 0.1543 | Val Loss: 0.1479\n",
            "üß† Epoch 13/15 | Train Loss: 0.2448 | Val Loss: 0.1990\n",
            "üß† Epoch 14/15 | Train Loss: 0.1803 | Val Loss: 0.1574\n",
            "üß† Epoch 15/15 | Train Loss: 0.2100 | Val Loss: 0.2178\n",
            "\n",
            "‚úÖ Accuracy: 0.9314\n",
            "\n",
            "‚úÖ Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "    Five-Memory       0.95      0.96      0.96       599\n",
            "    Nine-Memory       0.93      0.94      0.94       585\n",
            "Thirteen-Memory       0.91      0.90      0.90       564\n",
            "\n",
            "       accuracy                           0.93      1748\n",
            "      macro avg       0.93      0.93      0.93      1748\n",
            "   weighted avg       0.93      0.93      0.93      1748\n",
            "\n",
            "‚úÖ Confusion Matrix:\n",
            " [[574   3  22]\n",
            " [  7 549  29]\n",
            " [ 22  37 505]]\n",
            "\n",
            "‚öôÔ∏è Training Transformer_Memory with Early Stopping...\n",
            "üß† Epoch 1/15 | Train Loss: 0.6430 | Val Loss: 0.2423\n",
            "üß† Epoch 2/15 | Train Loss: 0.1919 | Val Loss: 0.1713\n",
            "üß† Epoch 3/15 | Train Loss: 0.1533 | Val Loss: 0.1637\n",
            "üß† Epoch 4/15 | Train Loss: 0.1413 | Val Loss: 0.1531\n",
            "üß† Epoch 5/15 | Train Loss: 0.1410 | Val Loss: 0.1378\n",
            "üß† Epoch 6/15 | Train Loss: 0.1292 | Val Loss: 0.1292\n",
            "üß† Epoch 7/15 | Train Loss: 0.1212 | Val Loss: 0.1250\n",
            "üß† Epoch 8/15 | Train Loss: 0.1220 | Val Loss: 0.1744\n",
            "üß† Epoch 9/15 | Train Loss: 0.1197 | Val Loss: 0.1736\n",
            "üß† Epoch 10/15 | Train Loss: 0.1428 | Val Loss: 0.1363\n",
            "üß† Epoch 11/15 | Train Loss: 0.1162 | Val Loss: 0.1308\n",
            "üß† Epoch 12/15 | Train Loss: 0.1174 | Val Loss: 0.1193\n",
            "üß† Epoch 13/15 | Train Loss: 0.0971 | Val Loss: 0.1477\n",
            "üß† Epoch 14/15 | Train Loss: 0.0982 | Val Loss: 0.1171\n",
            "üß† Epoch 15/15 | Train Loss: 0.0978 | Val Loss: 0.1100\n",
            "\n",
            "‚úÖ Accuracy: 0.9662\n",
            "\n",
            "‚úÖ Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "    Five-Memory       0.99      0.99      0.99       599\n",
            "    Nine-Memory       0.98      0.94      0.96       585\n",
            "Thirteen-Memory       0.93      0.97      0.95       564\n",
            "\n",
            "       accuracy                           0.97      1748\n",
            "      macro avg       0.97      0.97      0.97      1748\n",
            "   weighted avg       0.97      0.97      0.97      1748\n",
            "\n",
            "‚úÖ Confusion Matrix:\n",
            " [[592   0   7]\n",
            " [  0 552  33]\n",
            " [  9  10 545]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Prepare Balanced Binary Classifier Data (JustListen = 0, Memory = 1) ===\n",
        "X_bin, y_bin = [], []\n",
        "for subj_data in data:\n",
        "    for cond_idx in range(3):  # Conditions: Five, Nine, Thirteen\n",
        "        for trial_idx in range(54):\n",
        "            # JustListen = 0\n",
        "            sig_jl = subj_data[cond_idx, 0, trial_idx]\n",
        "            if not np.isnan(sig_jl).all():\n",
        "                X_bin.append(sig_jl)\n",
        "                y_bin.append(0)\n",
        "            # MemoryCorrect + MemoryIncorrect = 1\n",
        "            for subcond_idx in [1, 2]:\n",
        "                sig_mem = subj_data[cond_idx, subcond_idx, trial_idx]\n",
        "                if not np.isnan(sig_mem).all():\n",
        "                    X_bin.append(sig_mem)\n",
        "                    y_bin.append(1)\n",
        "\n",
        "X_bin = downsample_signals(clean_signals(np.array(X_bin)))\n",
        "label_names_bin = [\"JustListen\", \"Memory\"]\n",
        "\n",
        "# === Train Models ===\n",
        "train_model(X_bin, np.array(y_bin), label_names_bin, ECG1DCNN, \"1D_CNN_Binary\")\n",
        "train_model(X_bin, np.array(y_bin), label_names_bin, ECG_BiLSTM, \"BiLSTM_Binary\")\n",
        "train_model(X_bin, np.array(y_bin), label_names_bin, ECG_Transformer, \"Transformer_Binary\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5m6N006yWIX",
        "outputId": "ac4bce58-14c0-42a7-f87f-ac42e6933e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚öôÔ∏è Training 1D_CNN_Binary with Early Stopping...\n",
            "üß† Epoch 1/15 | Train Loss: 0.6992 | Val Loss: 0.7023\n",
            "üß† Epoch 2/15 | Train Loss: 0.6940 | Val Loss: 0.6973\n",
            "üß† Epoch 3/15 | Train Loss: 0.6935 | Val Loss: 0.7061\n",
            "üß† Epoch 4/15 | Train Loss: 0.6923 | Val Loss: 0.6852\n",
            "üß† Epoch 5/15 | Train Loss: 0.6924 | Val Loss: 0.7030\n",
            "üß† Epoch 6/15 | Train Loss: 0.6925 | Val Loss: 0.6983\n",
            "üß† Epoch 7/15 | Train Loss: 0.6925 | Val Loss: 0.6869\n",
            "üß† Epoch 8/15 | Train Loss: 0.6923 | Val Loss: 0.6863\n",
            "üß† Epoch 9/15 | Train Loss: 0.6919 | Val Loss: 0.6940\n",
            "‚èπÔ∏è Early stopping triggered.\n",
            "\n",
            "‚úÖ Accuracy: 0.5029\n",
            "\n",
            "‚úÖ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  JustListen       0.33      0.56      0.42       813\n",
            "      Memory       0.70      0.47      0.57      1748\n",
            "\n",
            "    accuracy                           0.50      2561\n",
            "   macro avg       0.52      0.52      0.49      2561\n",
            "weighted avg       0.58      0.50      0.52      2561\n",
            "\n",
            "‚úÖ Confusion Matrix:\n",
            " [[459 354]\n",
            " [919 829]]\n",
            "\n",
            "‚öôÔ∏è Training BiLSTM_Binary with Early Stopping...\n",
            "üß† Epoch 1/15 | Train Loss: 0.6936 | Val Loss: 0.6909\n",
            "üß† Epoch 2/15 | Train Loss: 0.6934 | Val Loss: 0.6874\n",
            "üß† Epoch 3/15 | Train Loss: 0.6931 | Val Loss: 0.6944\n",
            "üß† Epoch 4/15 | Train Loss: 0.6934 | Val Loss: 0.6893\n",
            "üß† Epoch 5/15 | Train Loss: 0.6933 | Val Loss: 0.6942\n",
            "üß† Epoch 6/15 | Train Loss: 0.6933 | Val Loss: 0.6903\n",
            "üß† Epoch 7/15 | Train Loss: 0.6933 | Val Loss: 0.6903\n",
            "‚èπÔ∏è Early stopping triggered.\n",
            "\n",
            "‚úÖ Accuracy: 0.6825\n",
            "\n",
            "‚úÖ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  JustListen       0.00      0.00      0.00       813\n",
            "      Memory       0.68      1.00      0.81      1748\n",
            "\n",
            "    accuracy                           0.68      2561\n",
            "   macro avg       0.34      0.50      0.41      2561\n",
            "weighted avg       0.47      0.68      0.55      2561\n",
            "\n",
            "‚úÖ Confusion Matrix:\n",
            " [[   0  813]\n",
            " [   0 1748]]\n",
            "\n",
            "‚öôÔ∏è Training Transformer_Binary with Early Stopping...\n",
            "üß† Epoch 1/15 | Train Loss: 0.7185 | Val Loss: 0.7055\n",
            "üß† Epoch 2/15 | Train Loss: 0.6956 | Val Loss: 0.7044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Prepare Combined 4-Class Classifier Data ===\n",
        "X_combined, y_combined = [], []\n",
        "combined_label_map = {\n",
        "    \"JustListen\": 0,\n",
        "    \"Five-Memory\": 1,\n",
        "    \"Nine-Memory\": 2,\n",
        "    \"Thirteen-Memory\": 3\n",
        "}\n",
        "\n",
        "for subj_data in data:\n",
        "    for cond_idx, condition in enumerate([\"Five\", \"Nine\", \"Thirteen\"]):\n",
        "        for trial_idx in range(54):\n",
        "            # JustListen case (subcond_idx = 0)\n",
        "            sig_jl = subj_data[cond_idx, 0, trial_idx]\n",
        "            if not np.isnan(sig_jl).all():\n",
        "                X_combined.append(sig_jl)\n",
        "                y_combined.append(0)\n",
        "\n",
        "            # Memory cases (subcond_idx in [1, 2])\n",
        "            for subcond_idx in [1, 2]:\n",
        "                sig_mem = subj_data[cond_idx, subcond_idx, trial_idx]\n",
        "                if not np.isnan(sig_mem).all():\n",
        "                    label = combined_label_map[f\"{condition}-Memory\"]\n",
        "                    X_combined.append(sig_mem)\n",
        "                    y_combined.append(label)\n",
        "\n",
        "# Preprocess\n",
        "X_combined = downsample_signals(clean_signals(np.array(X_combined)))\n",
        "label_names_combined = list(combined_label_map.keys())\n",
        "\n",
        "# === Train All 3 Models for Combined Classifier ===\n",
        "train_model(X_combined, np.array(y_combined), label_names_combined, ECG1DCNN, \"1D_CNN_Combined\")\n",
        "train_model(X_combined, np.array(y_combined), label_names_combined, ECG_BiLSTM, \"BiLSTM_Combined\")\n",
        "train_model(X_combined, np.array(y_combined), label_names_combined, ECG_Transformer, \"Transformer_Combined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkFf88_yyaB8",
        "outputId": "8afa1ea8-361e-4343-a858-f498372fb782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚öôÔ∏è Training 1D_CNN_Combined with Early Stopping...\n",
            "üß† Epoch 1/15 | Train Loss: 0.8164 | Val Loss: 0.8010\n",
            "üß† Epoch 2/15 | Train Loss: 0.7266 | Val Loss: 0.7408\n",
            "üß† Epoch 3/15 | Train Loss: 0.7014 | Val Loss: 0.7110\n",
            "üß† Epoch 4/15 | Train Loss: 0.6891 | Val Loss: 0.7277\n",
            "üß† Epoch 5/15 | Train Loss: 0.6674 | Val Loss: 0.7206\n",
            "üß† Epoch 6/15 | Train Loss: 0.6715 | Val Loss: 0.7034\n",
            "üß† Epoch 7/15 | Train Loss: 0.6658 | Val Loss: 0.7303\n",
            "üß† Epoch 8/15 | Train Loss: 0.6553 | Val Loss: 0.7066\n",
            "üß† Epoch 9/15 | Train Loss: 0.6517 | Val Loss: 0.6822\n",
            "üß† Epoch 10/15 | Train Loss: 0.6463 | Val Loss: 0.7005\n",
            "üß† Epoch 11/15 | Train Loss: 0.6440 | Val Loss: 0.6924\n",
            "üß† Epoch 12/15 | Train Loss: 0.6449 | Val Loss: 0.6954\n",
            "üß† Epoch 13/15 | Train Loss: 0.6399 | Val Loss: 0.6847\n",
            "üß† Epoch 14/15 | Train Loss: 0.6368 | Val Loss: 0.6880\n",
            "‚èπÔ∏è Early stopping triggered.\n",
            "\n",
            "‚úÖ Accuracy: 0.6669\n",
            "\n",
            "‚úÖ Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "     JustListen       0.34      0.04      0.07       813\n",
            "    Five-Memory       0.67      0.96      0.79       599\n",
            "    Nine-Memory       0.69      0.96      0.80       585\n",
            "Thirteen-Memory       0.67      0.96      0.79       564\n",
            "\n",
            "       accuracy                           0.67      2561\n",
            "      macro avg       0.60      0.73      0.61      2561\n",
            "   weighted avg       0.57      0.67      0.56      2561\n",
            "\n",
            "‚úÖ Confusion Matrix:\n",
            " [[ 31 281 247 254]\n",
            " [ 22 575   0   2]\n",
            " [ 16   0 561   8]\n",
            " [ 21   0   2 541]]\n",
            "\n",
            "‚öôÔ∏è Training BiLSTM_Combined with Early Stopping...\n",
            "üß† Epoch 1/15 | Train Loss: 1.0928 | Val Loss: 0.8511\n",
            "üß† Epoch 2/15 | Train Loss: 0.8644 | Val Loss: 0.8305\n",
            "üß† Epoch 3/15 | Train Loss: 0.7605 | Val Loss: 0.7772\n",
            "üß† Epoch 4/15 | Train Loss: 0.8531 | Val Loss: 0.7672\n",
            "üß† Epoch 5/15 | Train Loss: 0.7949 | Val Loss: 0.8158\n",
            "üß† Epoch 6/15 | Train Loss: 0.8046 | Val Loss: 0.7877\n",
            "üß† Epoch 7/15 | Train Loss: 0.7547 | Val Loss: 0.7460\n",
            "üß† Epoch 8/15 | Train Loss: 0.7985 | Val Loss: 0.7646\n",
            "üß† Epoch 9/15 | Train Loss: 0.7224 | Val Loss: 0.7451\n",
            "üß† Epoch 10/15 | Train Loss: 0.7017 | Val Loss: 0.7299\n",
            "üß† Epoch 11/15 | Train Loss: 0.7156 | Val Loss: 0.7369\n",
            "üß† Epoch 12/15 | Train Loss: 0.6855 | Val Loss: 0.7188\n",
            "üß† Epoch 13/15 | Train Loss: 0.6792 | Val Loss: 0.7128\n",
            "üß† Epoch 14/15 | Train Loss: 0.6725 | Val Loss: 0.7084\n",
            "üß† Epoch 15/15 | Train Loss: 0.6721 | Val Loss: 0.7042\n",
            "\n",
            "‚úÖ Accuracy: 0.6603\n",
            "\n",
            "‚úÖ Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "     JustListen       0.44      0.00      0.01       813\n",
            "    Five-Memory       0.67      0.96      0.79       599\n",
            "    Nine-Memory       0.69      0.96      0.80       585\n",
            "Thirteen-Memory       0.63      0.98      0.76       564\n",
            "\n",
            "       accuracy                           0.66      2561\n",
            "      macro avg       0.61      0.73      0.59      2561\n",
            "   weighted avg       0.59      0.66      0.54      2561\n",
            "\n",
            "‚úÖ Confusion Matrix:\n",
            " [[  4 280 246 283]\n",
            " [  2 578   0  19]\n",
            " [  1   0 559  25]\n",
            " [  2   2  10 550]]\n",
            "\n",
            "‚öôÔ∏è Training Transformer_Combined with Early Stopping...\n",
            "üß† Epoch 1/15 | Train Loss: 0.9158 | Val Loss: 0.7745\n",
            "üß† Epoch 2/15 | Train Loss: 0.7319 | Val Loss: 0.7285\n",
            "üß† Epoch 3/15 | Train Loss: 0.7066 | Val Loss: 0.7430\n",
            "üß† Epoch 4/15 | Train Loss: 0.6893 | Val Loss: 0.7160\n",
            "üß† Epoch 5/15 | Train Loss: 0.6826 | Val Loss: 0.7125\n",
            "üß† Epoch 6/15 | Train Loss: 0.6768 | Val Loss: 0.7144\n",
            "üß† Epoch 7/15 | Train Loss: 0.6720 | Val Loss: 0.7168\n",
            "üß† Epoch 8/15 | Train Loss: 0.6654 | Val Loss: 0.7261\n",
            "üß† Epoch 9/15 | Train Loss: 0.6647 | Val Loss: 0.7114\n",
            "üß† Epoch 10/15 | Train Loss: 0.6622 | Val Loss: 0.7177\n",
            "üß† Epoch 11/15 | Train Loss: 0.6533 | Val Loss: 0.6979\n",
            "üß† Epoch 12/15 | Train Loss: 0.6535 | Val Loss: 0.6975\n",
            "üß† Epoch 13/15 | Train Loss: 0.6486 | Val Loss: 0.6921\n",
            "üß† Epoch 14/15 | Train Loss: 0.6460 | Val Loss: 0.6996\n",
            "üß† Epoch 15/15 | Train Loss: 0.6481 | Val Loss: 0.6979\n",
            "\n",
            "‚úÖ Accuracy: 0.6654\n",
            "\n",
            "‚úÖ Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "     JustListen       0.43      0.00      0.01       813\n",
            "    Five-Memory       0.67      0.98      0.80       599\n",
            "    Nine-Memory       0.69      0.95      0.80       585\n",
            "Thirteen-Memory       0.64      0.98      0.78       564\n",
            "\n",
            "       accuracy                           0.67      2561\n",
            "      macro avg       0.61      0.73      0.59      2561\n",
            "   weighted avg       0.59      0.67      0.54      2561\n",
            "\n",
            "‚úÖ Confusion Matrix:\n",
            " [[  3 286 247 277]\n",
            " [  0 590   0   9]\n",
            " [  3   0 558  24]\n",
            " [  1   7   3 553]]\n"
          ]
        }
      ]
    }
  ]
}